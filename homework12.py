# -*- coding: utf-8 -*-
"""homework12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10rFB1htn7fCa8m84KPBZPUDuBVYqJQV4

**Homework 12.**

For this assignment, you won't need more than numpy:
"""

import numpy as np

"""In this assignment, you'll be creating three classes: `Linear`, `Softmax`, and `Model`. The `Linear` and `Softmax` classes will define layers of a Neural Network. The Model class defines a particular network, given a list of layers.

For example, consider the following code:
```
layer1=Linear(2,3)
layer2=Linear(3,10)
layer3=Softmax()
network=Model([layer1,layer2,layer3])
```

Here, layer1 takes a feature matrix with 2 columns (features), and produces a matrix with the same number of rows and 3 columns. layer2 then accepts that matrix, and produces one with 10 columns. Finally, the Softmax layer produces columns with positive values that sum to 1, representing the probability that each observation (row) is one of 10 possible classes.

All three classes (Linear and Softmax) should have a `predict` method. If `X` is a feature matrix of shape (n,2), then running `network.predict(X)` after the above code will call the `predict` methods of each layer, and produce a matrix of shape (n,10), of positive values, where each row sums to 1.

"""

class Linear():
  '''Fully connected linear layer class'''
  def __init__(self, input_size, output_size):
    np.random.seed(1) #Don't use in practice! This is just to make sure we all get the same answers
    self.weights = np.random.randn(input_size, output_size) * np.sqrt(2.0 / input_size) #Standard weight initialization
    self.biases = np.zeros(output_size) #Standard bias initialization

  def predict(self,input):
    return np.dot(input, self.weights) + self.biases

class Softmax():
  '''Implement Softmax as final layer for prediction only'''
  def __init__(self):
    pass #No init function necessary

  def predict(self,input):
    input=np.exp(input)
    return input/np.sum(input, axis=1, keepdims=True)

class Model():
  def __init__(self,layerlist):
    self.layerlist=layerlist

  def add(self,layer):
    self.layerlist+=[layer]

  def predict(self,input):
    for layer in self.layerlist:
        input = layer.predict(input)
    return input

"""Now test your code. Run this code block. You should see a matrix of shape (15,10), where each row sums to 1."""

np.random.seed(4)
X=np.random.random(30).reshape((15,2)) #generate a random feature matrix with 2 features, and 15 observations

layer1=Linear(2,3)
layer2=Linear(3,10)
layer3=Softmax()
network=Model([layer1,layer2,layer3])

network.predict(X)

"""To see this as predicted classes, rather than probabilities of each class, recall that you can use the argmax function to pick out the class with the highest probability for each observation:"""

np.argmax(network.predict(X),axis=1)

"""Without a softmax layer you can do regression tasks if the last layer outputs a single real number for each observation. Here we'll use the `add` method of the `Model` class to build a neural network one layer at a time, instead of all at once. This avoids having to name each layer."""

network2=Model([])
network2.add(Linear(2,10))
network2.add(Linear(10,1))

network2.predict(X)

"""In the next assignment, you'll add methods to your classes that adjust the weights and biases of each layer, so that your network genetrates predictions that match some target."""